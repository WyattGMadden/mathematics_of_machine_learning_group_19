{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "Lets input the mat file and check the dimensions of the array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io as scipy\n",
    "import numpy as np\n",
    "from pytictoc import TicToc as tictoc\n",
    "mat = scipy.loadmat('/Users/wyattmadden/Documents/school/' + \n",
    "                    'MSU/2020/m508/labs/lab_1/data.mat')\n",
    "X = mat['X']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we calculate the L2 of X using a for-loop to sum the euclidean distances. We see this gives us the expected output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for i in range(0, X.shape[1]):\n",
    "    s = s + np.linalg.norm(X[0:X.shape[0], i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we calculate the L2 of X using vectorized operations in NumPy, first calulating the sums of squares within the first dimension of X, resulting in a 1,000,000 length vector with values that are each the euclidean distance of 10 numbers, and then summing this vector. We see this results in the same value, as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1380518.375334337"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_L2_norms = np.linalg.norm(X, axis = 0)\n",
    "sum_of_squares = np.sum(vector_of_L2_norms)\n",
    "sum_of_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "Now lets run both calculations again, timing each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 4.679219 seconds.\n"
     ]
    }
   ],
   "source": [
    "non_vectorized_time = tictoc() \n",
    "\n",
    "non_vectorized_time.tic()\n",
    "\n",
    "s = 0\n",
    "for i in range(0, X.shape[1]):\n",
    "    s = s + np.linalg.norm(X[0:X.shape[0], i])\n",
    "    \n",
    "non_vectorized_time.toc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 0.112750 seconds.\n"
     ]
    }
   ],
   "source": [
    "vectorized_time = tictoc() \n",
    "\n",
    "vectorized_time.tic()\n",
    "\n",
    "vector_of_L2_norms = np.linalg.norm(X, axis = 0)\n",
    "sum_of_squares = np.sum(vector_of_L2_norms)\n",
    "    \n",
    "vectorized_time.toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the non-vectorized calculation took 3.58 seconds, while the non-vectorized calculation took only 0.05 seconds. The vectorized calculation was over 70 times faster than the non-vectorized calculation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
